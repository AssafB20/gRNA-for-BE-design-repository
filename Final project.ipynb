{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My postdoc research involves finding patients with retinal degenerative mutations that are amebale for base editing correction.\n",
    "Later, we would like to develop \"disease-in-a-dish\" model that recapitulates their degeneration features using iPSCs, and to try to reverse the disease phenotype by correction of the mutation using base editing techniques. Potentially, this kind of treatment will join the arsenal of genetic treatments like gene editing (Crispr-KO,i,a) and gene augmentation, that are either have already FDA approval (luxturna - gene augmentation using AAV for genetic retinal degenerative disease) or are on clinical trial phase (EDITAS's Crispr-KO of dominant genetic retinal degenerative disease).\n",
    "\n",
    "The first step in my research is to find the right candidates for the treatment. We work on a data base of patients that were found to have been diagnosed with retinal degeneration clinically, and had Whole Exome Sequencing that found the presumably causative pathologic point mutation.\n",
    "\n",
    "Base editing mechanism has several limitations:\n",
    "1. There are (at this point) mainly Adenine and Cytidine base editors. Adenine changes A/T to G/C. Cytidine C/G to T/A. That means that one can treat G/C to A/T or T/A to C/G mutations. {-/- the second (-) means the complement base}\n",
    "\n",
    "2. Each base editor has different activity window. That means that we can have unwanted editing of bases other than the point mutation - \"a bystander\"\n",
    "\n",
    "3. Base editors are part of complex that incorporates cas9, which guides together with the guide RNA the complex to the target mutation. cas9 is responsible to bind the PAM site downstream to the mutation. Each cas9 can bind specific PAM sequences.\n",
    "\n",
    "The way I used to check whether a patient fits for base editing is with a tool from a website (rgenome.net/be-designer/).\n",
    "It asks you to input a sequence (raw or fasta) and choose the type of cas9 and type of base editor.\n",
    "Unfortunately, there is no way to choose ALL the cas9 types in one step and there are 13 kinds of it, so for every sequence I had to run the website algorithm 13 times..And I had about 30 patient sequences.. \n",
    "The output of this program gives you the gRNA if it finds one for the respected input, activity window, and bystanders..\n",
    "The gRNA is usually 20 base long sequence DNA sequence upstream to the pam site. This sequence guides the BE complex to the complement strand of the mutation strand that we want to edit. The mutation should be in the activity window - for Adenine base editor is at positions 14-16 of the gRNA counting from the 3' end (= the pam site 5').\n",
    "\n",
    "For my final project I decided to design an algorithem that will receive a list of sequences where the pathogenic point mutation is the only one marked in capital letter. Another input is the type of base editor. The output will be a list of dictionaries where {seq(n): [cas9, gRNA, activity window, number of bystanders]} for each sequence in the input list in a \"results.txt\" text file, and in the return of the function for future coding manipulations.\n",
    "\n",
    "This way we can potentially save a lot of time in the next base editing target searches. The only time consuming in this process is tagging the pathogenic mutation with capital letter, but this is already how the person from the sequencing core plugging the reading to the data base.\n",
    "\n",
    "I did all the coding from scratch because I couldn't find any website or any paper that let you do exactly what I was trying to do, and also because there is no available code from the website I was using at rgenome.net/be-designer/ .\n",
    "\n",
    "I chose to use python because we were learning in class how to manipulate strings mainly in this language. I have found regex tools to be very efficient in manipulating long strings. Also, I ended up with few loops in my script, so this is another reason why choosing python for this task.\n",
    "\n",
    "The most \"labor intensive\" part of the code was to write donwn the dictionary \"pam\", which I did manually..I only realized mid-way that I could have write a function to do it..but it was too late.\n",
    "\n",
    "I compared my results file to the work I have already done before through the website, and I have found them to be identical.\n",
    "This new method will not only save time, but also solves the human error factor from doing multiple repetitions of copy pasting from the website to a file.\n",
    "\n",
    "I believe that after I add a feature for finding possible \"miss-matches\" throughout the whole genome (which I need to learn to do maybe with BioPython?), my script can be valuable for many people in this field who design their base editing experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam = {'xCas9':['a','c','g','t']}\n",
    "#{'spCas9':['agg','cgg','ggg','tgg'], \n",
    "       #'spCas9-VQR':['agaa','agac','agag','agat','cgaa','cgac','cgag','cgat','ggaa','ggac','ggag','ggat','tgaa','tgac','tgag','tgat'],\n",
    "      # 'spCas9-EQR':['agag','cgag','ggag','tgag'],'spCas9-VRER':['agcg','cgcg','ggcg','tgcg'],\n",
    "      # 'saCas9':['aagaat','aagagt','aaggat','aagggt','acgaat','acgagt','acggat','acgggt','aggaat','aggagt','agggat','aggggt','atgaat','atgagt','atggat','atgggt',\n",
    "         #        'cagaat','cagagt','caggat','cagggt','ccgaat','ccgagt','ccggat','ccgggt','cggaat','cggagt','cgggat','cggggt','ctgaat','ctgagt','ctggat','ctgggt',\n",
    "        #         'gagaat','gagagt','gaggat','gagggt','gcgaat','gcgagt','gcggat','gcgggt','gggaat','gggagt','ggggat','gggggt','gtgaat','gtgagt','gtggat','gtgggt',\n",
    "       #          'tagaat','tagagt','taggat','tagggt','tcgaat','tcgagt','tcggat','tcgggt','tggaat','tggagt','tgggat','tggggt','ttgaat','ttgagt','ttggat','ttgggt'],\n",
    "      # 'saCas9-KKH':\n",
    "             #   ['aaaaat','aaaagt','aaagat','aaaggt','acaaat','acaagt','acagat','acaggt','agaaat','agaagt','agagat','agaggt','ataaat','ataagt','atagat','ataggt',\n",
    "            #     'caaaat','caaagt','caagat','caaggt','ccaaat','ccaagt','ccagat','ccaggt','cgaaat','cgaagt','cgagat','cgaggt','ctaaat','ctaagt','ctagat','ctaggt',\n",
    "           #      'gaaaat','gaaagt','gaagat','gaaggt','gcaaat','gcaagt','gcagat','gcaggt','ggaaat','ggaagt','ggagat','ggaggt','gtaaat','gtaagt','gtagat','gtaggt',\n",
    "          #       'taaaat','taaagt','taagat','taaggt','tcaaat','tcaagt','tcagat','tcaggt','tgaaat','tgaagt','tgagat','tgaggt','ttaaat','ttaagt','ttagat','ttaggt',\n",
    "                 \n",
    "         #        'aacaat','aacagt','aacgat','aacggt','accaat','accagt','accgat','accggt','agcaat','agcagt','agcgat','agcggt','atcaat','atcagt','atcgat','atcggt',\n",
    "        #         'cacaat','cacagt','cacgat','cacggt','cccaat','cccagt','cccgat','cccggt','cgcaat','cgcagt','cgcgat','cgcggt','ctcaat','ctcagt','ctcgat','ctcggt',\n",
    "                # 'gacaat','gacagt','gacgat','gacggt','gccaat','gccagt','gccgat','gccggt','ggcaat','ggcagt','ggcgat','ggcggt','gtcaat','gtcagt','gtcgat','gtcggt',\n",
    "               #  'tacaat','tacagt','tacgat','tacggt','tccaat','tccagt','tccgat','tccggt','tgcaat','tgcagt','tgcgat','tgcggt','ttcaat','ttcagt','ttcgat','ttcggt',\n",
    "           \n",
    "              #   'aagaat','aagagt','aaggat','aagggt','acgaat','acgagt','acggat','acgggt','aggaat','aggagt','agggat','aggggt','atgaat','atgagt','atggat','atgggt',\n",
    "             #    'cagaat','cagagt','caggat','cagggt','ccgaat','ccgagt','ccggat','ccgggt','cggaat','cggagt','cgggat','cggggt','ctgaat','ctgagt','ctggat','ctgggt',\n",
    "            #     'gagaat','gagagt','gaggat','gagggt','gcgaat','gcgagt','gcggat','gcgggt','gggaat','gggagt','ggggat','gggggt','gtgaat','gtgagt','gtggat','gtgggt',\n",
    "           #      'tagaat','tagagt','taggat','tagggt','tcgaat','tcgagt','tcggat','tcgggt','tggaat','tggagt','tgggat','tggggt','ttgaat','ttgagt','ttggat','ttgggt',\n",
    "\n",
    "          #       'aataat','aatagt','aatgat','aatggt','actaat','actagt','actgat','actggt','agtaat','agtagt','agtgat','agtggt','attaat','attagt','attgat','attggt',\n",
    "         #        'cataat','catagt','catgat','catggt','cctaat','cctagt','cctgat','cctggt','cgtaat','cgtagt','cgtgat','cgtggt','cttaat','cttagt','cttgat','cttggt',\n",
    "        #         'gataat','gatagt','gatgat','gatggt','gctaat','gctagt','gctgat','gctggt','ggtaat','ggtagt','ggtgat','ggtggt','gttaat','gttagt','gttgat','gttggt',\n",
    "       #          'tataat','tatagt','tatgat','tatggt','tctaat','tctagt','tctgat','tctggt','tgtaat','tgtagt','tgtgat','tgtggt','tttaat','tttagt','tttgat','tttggt'\n",
    "        #        ],\n",
    "       #'xCas9':['agt','cgt','ggt','tgt'],\n",
    "       \n",
    "       #'Cas9-NG (NGK>NGM)':['ag','cg','gg','tg']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SpCas9 from Streptococcus pyogenes: 5'-NGG-3'\n",
    "\n",
    "SpCas9-VQR from Streptococcus pyogenes: 5'-NGAN-3'\n",
    "\n",
    "SpCas9-EQR from Streptococcus pyogenes: 5'-NGAG-3'\n",
    "\n",
    "SpCas9-VRER from Streptococcus pyogenes: 5'-NGCG-3'\n",
    "\n",
    "SaCas9 from Staphylococcus aureus: 5'-NNGRRT-'3\n",
    "\n",
    "SaCas9-KKH from Staphylococcus aureus: 5'-NNNRRT-'3\n",
    "\n",
    "xCas9 3.7 (TLIKDIV SpCas9) from Streptococcus pyogenes: 5'-NGT-3'\n",
    "\n",
    "N - any base\n",
    "\n",
    "R - A or G\n",
    "\n",
    "K - G or T\n",
    "\n",
    "M - A or C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_strand(strand):  #this function gets a sequence and returns its complement strand with keeping the mutation in capital.\n",
    " old_chars = \"TGacgt\"\n",
    " replace_chars = \"ACtgca\"\n",
    " tab = str.maketrans(old_chars,replace_chars)\n",
    " return strand.translate(tab)[::-1]   # returns the complement strand 5' -> 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetfinder(filename): #filename - a text file with a list of sequences with mutation in capital letter, be - base-editor\n",
    "    be = input('for adenine base editing send a, for cytidine base editing send c: ')\n",
    "    import re\n",
    "    y={}\n",
    "    x=0\n",
    "    mut_loc=0\n",
    "    f= open('results.txt','w')\n",
    "    temp = open(filename,'r').read().split('\\n\\n')       #the seqs in the file are separated by blank lines..so split the seqs\n",
    "    for seq in temp:\n",
    "        seq = seq.replace(\" \",\"\")             # for each seq, ignore the spaces within\n",
    "        if be == 'a':                       # input 'a' was for adenine base editor\n",
    "            mut_loc = seq.find('A')            # find the position of 'A' in the seq - which is the ONLY capital letter in it\n",
    "            win = [14,15,16]                 # the activity window of adenine base editor\n",
    "            if mut_loc == -1:               # if it didn't find 'A' in the seq, I guess the user gave us a strand with a 'T' mutation\n",
    "                seq = comp_strand(seq)      # call a function that will give the complement strand, but keep the mutation in capital letter \n",
    "                mut_loc = seq.find('A')     # and now search for the 'A' position\n",
    "                \n",
    "        if be == 'c':                      # same goes for c base editor\n",
    "            mut_loc = seq.find('C')\n",
    "            win = [13,14,15,16,17,18,19]\n",
    "            if mut_loc == -1:\n",
    "                seq = comp_strand(seq)\n",
    "                mut_loc = seq.find('C')\n",
    "        \n",
    "        for key, value in pam.items():                # pam is a dic with key-cas9 and values-their pam sites\n",
    "                for p in value:                       \n",
    "                    for x in re.finditer(p, seq[mut_loc:]):           # for every pam sites that is located AFTER the mutation position...because base editors' pams are downstream to the mutation\n",
    "                        x = x.start() + mut_loc                       # x is the position of the first base of the pam site\n",
    "                        if mut_loc in range(x-win[-1],x-win[0]+1):          # if the mutation located in the activity window\n",
    "                            bystand = seq.count(be,x-win[-1],x-win[0]+1)    # search for another 'a' (or 'c') in this window\n",
    "                            editwin = seq[x-win[-1]:x-win[0]+1]             # the window sequence itself\n",
    "                            y.setdefault(seq,[]).append([key,'5-'+seq[x-20:x+len(p)]+'-3',editwin,bystand]) # append to a dic where key is the seq, values are the type of cas9, gRNA, editing window, how many if any bystanders\n",
    "                        \n",
    "    for k,v in y.items():\n",
    "        f.write(str(k) + ' >>> ' + str(v) + '\\n\\n')          #write the results (list of dic items) to a text file\n",
    "                          \n",
    "    open(filename,'r').close()\n",
    "    f.close()\n",
    "    return y           #besides writing it to a text file, I thought it was important to return the list for future coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for adenine base editing send a, for cytidine base editing send c: a\n"
     ]
    }
   ],
   "source": [
    "y=targetfinder('patients.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blatofftarget(dic):\n",
    "    grna=[]\n",
    "    from selenium import webdriver\n",
    "    browser = webdriver.Firefox(executable_path=r\"C:\\Users\\abeck\\Desktop\\BE target analysis\\geckodriver.exe\")\n",
    "    browser.get('https://genome.ucsc.edu/cgi-bin/hgBlat')\n",
    "    textarea = browser.find_element_by_css_selector('textarea')\n",
    "    for key,value in dic.items():\n",
    "        for element in value:\n",
    "            if element[1] not in grna:\n",
    "                grna.append(element[1])\n",
    "    for x in grna[-25:]:\n",
    "        textarea.send_keys('>'+x+'\\n'+x+'\\n')\n",
    "    textarea.submit()\n",
    "    return grna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-aacagAtgtagttctgagtgtgg-3',\n",
       " '5-acagAtgtagttctgagtgtggt-3',\n",
       " '5-acagAtgtagttctgagtgtgg-3',\n",
       " '5-aacagAtgtagttctgagtgtg-3',\n",
       " '5-gaagcActccaggagggcctcg-3',\n",
       " '5-tttcaAaacagccatttttctgac-3',\n",
       " '5-tttcaAaacagccatttttctg-3',\n",
       " '5-cagctAgggtgttctgtgattg-3',\n",
       " '5-ctgcAcagcgtcagcaccgcagt-3',\n",
       " '5-ctgcAcagcgtcagcaccgcag-3',\n",
       " '5-ccagcAaagacgaagatgtgagt-3',\n",
       " '5-ccagcAaagacgaagatgtgag-3',\n",
       " '5-ggtgAcctacctgacaagcaagag-3',\n",
       " '5-ggtgAcctacctgacaagcaag-3',\n",
       " '5-tggccAtggtggctgatgatggg-3',\n",
       " '5-ctggccAtggtggctgatgatgg-3',\n",
       " '5-ctggccAtggtggctgatgatggggt-3',\n",
       " '5-tggccAtggtggctgatgatgg-3',\n",
       " '5-ctggccAtggtggctgatgatg-3',\n",
       " '5-gttaaAgtaagaacataggccgt-3',\n",
       " '5-gttaaAgtaagaacataggccg-3',\n",
       " '5-gtgtcActtccctacagggccgt-3',\n",
       " '5-gtgtcActtccctacagggccg-3',\n",
       " '5-aaccAtgacactctattatcag-3',\n",
       " '5-ggtgaAtggcctgagacttcagcg-3',\n",
       " '5-gtgaAtggcctgagacttcagcgagt-3',\n",
       " '5-ggtgaAtggcctgagacttcag-3',\n",
       " '5-ccagcAgtgataaggccaacag-3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blatofftarget(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
